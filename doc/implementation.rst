
======================
Implementation Details
======================


Gaussian Mixture Models
=======================

To be done


Intersession Variability Model (ISV)
====================================

Inter-Session Variability (ISV) modeling [Cool2013]_ is a session variability modeling technique built on top of the Gaussian mixture modeling approach.
It hypothesizes that within-class variations are embedded in a linear subspace in the GMM means subspace and these variations can be suppressed by an offset w.r.t each mean during the MAP adaptation.

In this generative model each sample is assumed to have been generated by a GMM mean supervector with the following shape: :math:`\mu_{i, j} = m + Ux_{i, j} + D_z{i}`, where :math:`m` is our prior, :math:`Ux_{i, j}` is the session offset that we want to suppress and :math:`D_z{i}` is the class offset (with all session effects suppressed).

All possible sources of session variations is embedded in this matrix :math:`U`.
Follow bellow an intuition of what is modeled with :math:`U` in the Iris flower `dataset <https://en.wikipedia.org/wiki/Iris_flower_data_set>`_.
The arrows :math:`U_{1}`, :math:`U_{2}` and :math:`U_{3}` are the directions of the within class variations, with respect to each Gaussian component, that will be suppressed a posteriori.

.. plot:: plot/plot_ISV.py
   :include-source: False


Joint Factor Analysis (JFA)
===========================


Joint Factor Analysis (JFA) [Kenny2007]_ is an extension of ISV. 
Besides the within-class assumption (modeled with :math:`U`), it also hypothesize that between class variations are embedded in a low rank rectangular matrix
:math:`V`.
In the supervector notation, this modeling has the following shape: :math:`\mu_{i, j} = m + Ux_{i, j}  + Vy_{i} + D_z{i}`.

Follow bellow an intuition of what is modeled with :math:`U` and :math:`V` in the Iris flower
`dataset <https://en.wikipedia.org/wiki/Iris_flower_data_set>`_. 
The arrows :math:`V_{1}`, :math:`V_{2}` and :math:`V_{3}` are the directions of the
between class variations with respect to each Gaussian component that will be
added a posteriori.

.. plot:: plot/plot_JFA.py
   :include-source: False


Total variability Modelling
===========================

Total Variability (TV) modeling [Dehak2011]_ is a front-end initially introduced for speaker recognition, which aims at describing samples by vectors of low
dimensionality called ``i-vectors``.
The model consists of a subspace :math:`T` and a residual diagonal covariance matrix :math:`\Sigma`, that are then used to extract i-vectors, and is built upon the GMM approach.
In the supervector notation this modeling has the following shape: :math:`\mu = m + Tv`.

Follow bellow an intuition of the data from the Iris flower `dataset <https://en.wikipedia.org/wiki/Iris_flower_data_set>`_, embedded in
the iVector space.

.. plot:: plot/plot_iVector.py
   :include-source: False



.. include:: links.rst
